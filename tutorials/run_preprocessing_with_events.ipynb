{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline\n",
    "\n",
    "\n",
    "This pipeline aims to serve as a semiautomatic and reproducible framework for preprocessing EEG signals prior to time-frequency-based analyses. It minimizes the manual steps required to clean the data based on visual inspection. It is advised to revisit the cleaned epochs before writing the final preprocessed file. \n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Temporal filtering  \n",
    "High-frequency artefacts and slow drifts are removed with a zero-phase bandpass filter using mne-Python [1]. The cutoff frequencies (0.5 - 45 Hz) can be modified in the utils folder in the configuration file (config.py). \n",
    "\n",
    "2. Create epochs  \n",
    "Epochs are nonoverlapping data segments created from the continuous data with a duration of 1 seconds. The length of epochs can be changed in the configuration file.\n",
    "Epochs can be created from (1) events; there is a custom method that created epochs based on annotations in the raw data, (2) without events, data segments are created from the beginning of the raw data. \n",
    "\n",
    "3. Outlier data rejection  \n",
    "3.1. Preliminar rejection  \n",
    "Epochs are rejected based on a global threshold on the z-score (> 3) of the epoch variance and amplitude range.\n",
    "3.2. ICA decomposition  \n",
    "The default method is the infomax algorithm, however it can be changed in the configuration file along with the number of components and the decimation parameter. Components containing blink artefacts are automatically marked with mne-Python.\n",
    "The ICA sourced can be visualized and interactively selected and rejected based on their topographies, time-courses or frequency spectra. The number of components that were removed from the data are documented in the “description” field of the epochs instance “info” structure.\n",
    "3.3. Autoreject  \n",
    "Autoreject [2, 3] uses unsupervised learning to estimate the rejection threshold for the epochs. In order to reduce computation time that increases with the number of segments and channels, autoreject can be fitted on a representative subset of epochs (25% of total epochs). Once the parameters are learned, the solution can be applied to any data that contains channels that were used during fit.\n",
    "4. Outlier channel interpolation  \n",
    "The Random Sample Consensus (RANSAC) algorithm [4] selects a random subsample of good channels to make predictions of each channel in small non-overlapping 4 seconds long time windows. It uses a method of spherical splines (Perrin et al., 1989) to interpolate the bad sensors. The sensors that were interpolated are added to the \"description\" field of the epochs \"info\" structure. \n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower);    \n",
    "\n",
    "switch to ```%matplotlib inline``` for (faster) static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from eeg_preprocessing.preprocessing import *\n",
    "from eeg_preprocessing.utils.events import get_events_from_raw, create_epochs_from_events\n",
    "from eeg_preprocessing.utils.io_raw import read_raw\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "\n",
    "EEG data can be imported using the custom read_raw() method that accepts BrainVision (.vhdr) and EDF (.edf) format. However, this custom method can be replaced and MNE functions used to import other file formats.\n",
    "\n",
    "See [this](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html) documentation for help with importing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e88ead21b947889784f9f1454419d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Volumes/crnl-memo-hd/TMS_rewiring/Raw_data', filename='', title='HTML(value='', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set base path to EEG data\n",
    "base_path = '/Volumes/crnl-memo-hd/TMS_rewiring/Raw_data'\n",
    "\n",
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Volumes/crnl-memo-hd/TMS_rewiring/Raw_data/15_L/Day1/EEG/15_L_Day1.vhdr...\n",
      "Setting channel info structure...\n",
      "<Info | 12 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, Pz, P3, ...\n",
      " chs: 64 EEG\n",
      " condition: L\n",
      " custom_ref_applied: False\n",
      " dig: 64 items (64 EEG)\n",
      " fid: 15_L_Day1\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: 2020-10-26 09:34:10 UTC\n",
      " nchan: 64\n",
      " num_day: 1\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      " subject: 15\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "# Load selected file\n",
    "raw = read_raw(raw_file_path=fc.selected, add_info=True)\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Extract triggers from raw instance\n",
    "events = get_events_from_raw(raw)\n",
    "\n",
    "resting_event_names = events.loc[events['event'].str.contains('rs_'), 'event'].tolist()\n",
    "asrt_event_names = events.loc[events['event'].str.contains('asrt_'), 'event'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event</th>\n",
       "      <th>sequence</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>1167.746</td>\n",
       "      <td>91</td>\n",
       "      <td>asrt_1_1</td>\n",
       "      <td>A</td>\n",
       "      <td>1282.248</td>\n",
       "      <td>114.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1324.152</td>\n",
       "      <td>91</td>\n",
       "      <td>asrt_1_1</td>\n",
       "      <td>A</td>\n",
       "      <td>1438.654</td>\n",
       "      <td>114.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1477.654</td>\n",
       "      <td>91</td>\n",
       "      <td>asrt_1_1</td>\n",
       "      <td>A</td>\n",
       "      <td>1592.106</td>\n",
       "      <td>114.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1633.542</td>\n",
       "      <td>91</td>\n",
       "      <td>asrt_1_1</td>\n",
       "      <td>A</td>\n",
       "      <td>1748.062</td>\n",
       "      <td>114.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1790.782</td>\n",
       "      <td>91</td>\n",
       "      <td>asrt_1_1</td>\n",
       "      <td>A</td>\n",
       "      <td>1905.468</td>\n",
       "      <td>114.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2092.350</td>\n",
       "      <td>93</td>\n",
       "      <td>asrt_1_2</td>\n",
       "      <td>A</td>\n",
       "      <td>2206.820</td>\n",
       "      <td>114.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>2256.246</td>\n",
       "      <td>93</td>\n",
       "      <td>asrt_1_2</td>\n",
       "      <td>A</td>\n",
       "      <td>2370.648</td>\n",
       "      <td>114.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2416.140</td>\n",
       "      <td>93</td>\n",
       "      <td>asrt_1_2</td>\n",
       "      <td>A</td>\n",
       "      <td>2530.558</td>\n",
       "      <td>114.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2579.734</td>\n",
       "      <td>93</td>\n",
       "      <td>asrt_1_2</td>\n",
       "      <td>A</td>\n",
       "      <td>2694.236</td>\n",
       "      <td>114.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>2740.828</td>\n",
       "      <td>93</td>\n",
       "      <td>asrt_1_2</td>\n",
       "      <td>A</td>\n",
       "      <td>2855.346</td>\n",
       "      <td>114.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>2918.514</td>\n",
       "      <td>95</td>\n",
       "      <td>asrt_1_3</td>\n",
       "      <td>A</td>\n",
       "      <td>3032.966</td>\n",
       "      <td>114.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>3092.888</td>\n",
       "      <td>95</td>\n",
       "      <td>asrt_1_3</td>\n",
       "      <td>A</td>\n",
       "      <td>3207.340</td>\n",
       "      <td>114.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>3255.800</td>\n",
       "      <td>95</td>\n",
       "      <td>asrt_1_3</td>\n",
       "      <td>A</td>\n",
       "      <td>3370.518</td>\n",
       "      <td>114.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>3423.132</td>\n",
       "      <td>95</td>\n",
       "      <td>asrt_1_3</td>\n",
       "      <td>A</td>\n",
       "      <td>3537.618</td>\n",
       "      <td>114.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>3593.350</td>\n",
       "      <td>95</td>\n",
       "      <td>asrt_1_3</td>\n",
       "      <td>A</td>\n",
       "      <td>3707.786</td>\n",
       "      <td>114.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>4087.832</td>\n",
       "      <td>97</td>\n",
       "      <td>asrt_1_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4202.400</td>\n",
       "      <td>114.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>4245.422</td>\n",
       "      <td>97</td>\n",
       "      <td>asrt_1_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4359.874</td>\n",
       "      <td>114.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>4404.430</td>\n",
       "      <td>97</td>\n",
       "      <td>asrt_1_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4519.082</td>\n",
       "      <td>114.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>4586.660</td>\n",
       "      <td>97</td>\n",
       "      <td>asrt_1_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4701.046</td>\n",
       "      <td>114.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>4742.950</td>\n",
       "      <td>97</td>\n",
       "      <td>asrt_1_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4857.618</td>\n",
       "      <td>114.668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_time  event_id     event sequence  end_time  duration\n",
       "805     1167.746        91  asrt_1_1        A  1282.248   114.502\n",
       "1068    1324.152        91  asrt_1_1        A  1438.654   114.502\n",
       "1331    1477.654        91  asrt_1_1        A  1592.106   114.452\n",
       "1595    1633.542        91  asrt_1_1        A  1748.062   114.520\n",
       "1860    1790.782        91  asrt_1_1        A  1905.468   114.686\n",
       "2128    2092.350        93  asrt_1_2        A  2206.820   114.470\n",
       "2391    2256.246        93  asrt_1_2        A  2370.648   114.402\n",
       "2652    2416.140        93  asrt_1_2        A  2530.558   114.418\n",
       "2915    2579.734        93  asrt_1_2        A  2694.236   114.502\n",
       "3179    2740.828        93  asrt_1_2        A  2855.346   114.518\n",
       "3444    2918.514        95  asrt_1_3        A  3032.966   114.452\n",
       "3709    3092.888        95  asrt_1_3        A  3207.340   114.452\n",
       "3973    3255.800        95  asrt_1_3        A  3370.518   114.718\n",
       "4241    3423.132        95  asrt_1_3        A  3537.618   114.486\n",
       "4504    3593.350        95  asrt_1_3        A  3707.786   114.436\n",
       "4768    4087.832        97  asrt_1_4        A  4202.400   114.568\n",
       "5033    4245.422        97  asrt_1_4        A  4359.874   114.452\n",
       "5299    4404.430        97  asrt_1_4        A  4519.082   114.652\n",
       "5564    4586.660        97  asrt_1_4        A  4701.046   114.386\n",
       "5826    4742.950        97  asrt_1_4        A  4857.618   114.668"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to show events\n",
    "events.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut raw data and create epochs based on triggers\n",
    "\n",
    "### Create epochs\n",
    "\n",
    "- bandpass filter the continuous data (0.5 - 45 Hz)\n",
    "- create fixed length epochs (1 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs = create_epochs_from_events(raw=raw, events=events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs['asrt_2_1'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "\n",
    "\n",
    "### 1.1. Preliminary epoch rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_faster = prepare_epochs_for_ica(epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run ICA\n",
    "\n",
    "We run ICA for the resting and ASRT periods together; it will take a few minutes.\n",
    "The parameters are: 32 ICA components using [\"infomax\"](https://mne.tools/stable/generated/mne.preprocessing.infomax.html) algorithm. \n",
    "\n",
    "When visualizing the components, it is recommended to subset the data (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ica = run_ica(epochs=epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualize components on epochs\n",
    "# Subset epochs to reduce execution time\n",
    "subset = [asrt_event_names[1]]\n",
    "# Exclude components by selecting them, right click on component name to visulize source:\n",
    "ica.plot_sources(epochs_faster[subset], start=0, stop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "# Document the number of excluded components\n",
    "ica.apply(epochs_faster)\n",
    "epochs_faster.info['description'] = f'n_components: {len(ica.exclude)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualize ICA cleaned epochs (optional)\n",
    "\n",
    "This step can be repeated after each preprocessing step, or you can also do a final inspection at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_faster['asrt_2_2'].plot(n_epochs=10, scalings={'eeg': 20e-6}, title=raw.info['fid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "\n",
    "# If you found a component that should have been excluded but it wasn't you can exclude it here:\n",
    "ica.plot_sources(epochs_faster['rs_3_1'], start=0, stop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "\n",
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "# Document the number of excluded components\n",
    "ica.apply(epochs_rs_faster)\n",
    "epochs_rs_faster.info['description'] = f'n_components: {len(ica.exclude)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save cleaned epochs (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "interim_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "\n",
    "\n",
    "# Create path to epoch files\n",
    "interim_epochs_path = os.path.join(interim_path, raw.info['condition'], 'epochs')\n",
    "if not os.path.exists(interim_epochs_path):\n",
    "    os.makedirs(interim_epochs_path)\n",
    "\n",
    "# Save ICA cleaned epochs \n",
    "fid = epochs_faster.info['fid']\n",
    "epochs_clean_fname = f'{fid}_ICA'\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_faster.save(os.path.join(interim_epochs_path, f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ar = run_autoreject(epochs_faster, n_jobs=11, subset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Drop bad epochs (stage 1)\n",
    "\n",
    "reject_log = ar.get_reject_log(epochs_faster)\n",
    "\n",
    "epochs_autoreject = epochs_faster.copy().drop(reject_log.bad_epochs, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Drop bad epochs (stage 2) - after visual inspection\n",
    "idx = np.where(np.count_nonzero(reject_log.labels, axis=1) > epochs_faster.info['nchan']/2)[0].tolist()\n",
    "\n",
    "# # Plot just the bad epochs!\n",
    "if idx: \n",
    "    epochs_faster[idx].plot(n_epochs=10,\n",
    "                                scalings={'eeg': 20e-6},\n",
    "                                n_channels=32)\n",
    "    \n",
    "epochs_autoreject.drop(idx, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_autoreject.drop(idx, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_autoreject['asrt_2_1'].plot(n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# save clean epochs\n",
    "fid = epochs_autoreject.info['fid']\n",
    "epochs_clean_fname = f'{fid}_ICA_autoreject'\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_autoreject.save(os.path.join(interim_epochs_path, f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_ransac = run_ransac(epochs_autoreject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# inspect which sensors were interpolated (if any)\n",
    "epochs_ransac.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final visual inspection\n",
    "\n",
    "Mark epochs that should be dropped, select electrodes that should be interpolated etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_ransac.plot(n_epochs=10,\n",
    "                       n_channels=32,\n",
    "                       # group_by='position',\n",
    "                       scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# if there are additional channels marked for interpolation, we can interpolate them here.\n",
    "\n",
    "if epochs_ransac.info['bads']:\n",
    "    bads_str = ', '.join(epochs_ransac.info['bads'])\n",
    "    epochs_ransac.interpolate_bads()\n",
    "    epochs_ransac.info.update(description=epochs_ransac.info['description'] + ', interpolated: ' + bads_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Set average reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_ransac.set_eeg_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Annotate continuous data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_times = [epochs.events[idx][0] / raw.info['sfreq'] \n",
    "               for idx, value in enumerate(epochs_ransac.drop_log) if value]\n",
    "\n",
    "duration = (epochs_ransac.events[1][0] - epochs_ransac.events[0][0]) / raw.info['sfreq'] \n",
    "\n",
    "raw.annotations.append(onset=start_times,\n",
    "                       duration=[duration] * len(start_times),\n",
    "                       description='BAD_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create path to annotated files\n",
    "annotated_raw_path = os.path.join(interim_path, raw.info['condition'], 'raw')\n",
    "if not os.path.exists(annotated_raw_path):\n",
    "    os.makedirs(annotated_raw_path)\n",
    "\n",
    "# Save annotated continuous data\n",
    "fid = raw.info[\"fid\"]\n",
    "raw_annotated_fname = f'{fid}_bad_annotated'\n",
    "postfix = '-raw.fif.gz'\n",
    "raw.save(os.path.join(annotated_raw_path, f'{raw_annotated_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save cleaned epochs\n",
    "\n",
    "#### 7.1. Resting period before ASRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create path to annotated files\n",
    "epochs_rs_path = os.path.join(interim_path, raw.info['condition'], 'epochs_rs')\n",
    "if not os.path.exists(epochs_rs_path):\n",
    "    os.makedirs(epochs_rs_path)\n",
    "\n",
    "rs_period_name = f'rs_{raw.info[\"num_day\"]}_1'\n",
    "fid = f'{raw.info[\"subject\"]}_{raw.info[\"condition\"]}_{rs_period_name}'\n",
    "epochs_clean_fname = f'{fid}_ICA_autoreject_ransac'\n",
    "postfix = '-epo.fif.gz'\n",
    "\n",
    "epochs_ransac[rs_period_name].save(os.path.join(epochs_rs_path, f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Resting period before ASRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rs_period_name = f'rs_{raw.info[\"num_day\"]}_2'\n",
    "fid = f'{raw.info[\"subject\"]}_{raw.info[\"condition\"]}_{rs_period_name}'\n",
    "epochs_clean_fname = f'{fid}_ICA_autoreject_ransac'\n",
    "postfix = '-epo.fif.gz'\n",
    "\n",
    "epochs_ransac[rs_period_name].save(os.path.join(epochs_rs_path,\n",
    "                                                f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. ASRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create path to annotated files\n",
    "epochs_asrt_path = os.path.join(interim_path, raw.info['condition'], 'epochs_asrt')\n",
    "if not os.path.exists(epochs_asrt_path):\n",
    "    os.makedirs(epochs_asrt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for sequence, periods in events.groupby('sequence')['event'].apply(set).to_dict().items():\n",
    "    #epochs_to_merge = [epochs_ransac[period] for period in periods]\n",
    "    #merged_epochs = mne.concatenate_epochs(epochs_to_merge, offset=True)\n",
    "    fid = f'{raw.info[\"subject\"]}_{raw.info[\"condition\"]}_asrt_{raw.info[\"num_day\"]}_{sequence}'\n",
    "    epochs_clean_fname = f'{fid}_ICA_autoreject_ransac'\n",
    "    postfix = '-epo.fif.gz'\n",
    "    \n",
    "    epochs_ransac[sorted(set(periods))].save(os.path.join(epochs_asrt_path,\n",
    "                                                          f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# cleanup from memory\n",
    "del raw, epochs, epochs_autoreject, epochs_ransac\n",
    "\n",
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
