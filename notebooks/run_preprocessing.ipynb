{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline\n",
    "\n",
    "The goal of this pipeline is to produce data that is clean enough to be further analyzed in ERP or connectivity analyses. This pipeline is semi-automatic; manual steps are not necessarily required, but it is advised to revisit the cleaned epochs. ICA components have to be selected manually.\n",
    "\n",
    "## Outline\n",
    "\n",
    "Suggestions from this [paper](https://www.biorxiv.org/content/10.1101/240044v1.full.pdf)\n",
    "- apply bandpass filter (0.5 - 45Hz) on continuous data\n",
    "- create fixed length epochs \n",
    "- preliminary bad epoch rejection\n",
    "- fit ICA on cleaned data segments\n",
    "- mark components based on visual inspection\n",
    "- apply ICA on epochs\n",
    "- run [autoreject](https://www.sciencedirect.com/science/article/abs/pii/S1053811917305013) \n",
    "- find and interpolate bad sensors\n",
    "\n",
    "## References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install package requirements\n",
    "\n",
    "Can be ignored if requirements are already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower); \n",
    "switch to ```%matplotlib inline``` for (faster) static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from eeg_preprocessing.preprocessing import *\n",
    "from eeg_preprocessing.utils.events import get_events_from_raw, create_epochs_from_events\n",
    "from eeg_preprocessing.utils.io_raw import read_raw\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base path to EEG data\n",
    "base_path = '/Volumes/crnl-memo-hd/TMS_rewiring/Raw_data'\n",
    "\n",
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "interim_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected file\n",
    "raw = read_raw(raw_file_path=fc.selected, add_info=False)\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract triggers from raw instance\n",
    "events = get_events_from_raw(raw)\n",
    "\n",
    "resting_event_names = events.loc[events['event'].str.contains('rs_'), 'event'].tolist()\n",
    "asrt_event_names = events.loc[events['event'].str.contains('asrt_'), 'event'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to show events\n",
    "events.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut raw data and create epochs based on triggers\n",
    "\n",
    "### Create epochs\n",
    "\n",
    "- bandpass filter the continuous data (0.5 - 45 Hz)\n",
    "- create fixed length epochs (1 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = create_epochs_from_events(raw=raw, events=events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "\n",
    "\n",
    "### 1.1. Preliminary epoch rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_faster = prepare_epochs_for_ica(epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run ICA\n",
    "\n",
    "We run ICA for the resting and ASRT periods together; it will take a few minutes.\n",
    "The parameters are: 32 ICA components using [\"infomax\"](https://mne.tools/stable/generated/mne.preprocessing.infomax.html) algorithm. \n",
    "\n",
    "When visualizing the components, it is recommended to subset the data (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = run_ica(epochs=epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize components on epochs\n",
    "# Subset epochs to reduce execution time\n",
    "subset = resting_event_names + [asrt_event_names[0]]\n",
    "# Exclude components by selecting them, right click on component name to visulize source:\n",
    "ica.plot_sources(epochs_faster, start=0, stop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "# Document the number of excluded components\n",
    "ica.apply(epochs_faster)\n",
    "epochs_faster.info['description'] = f'n_components: {len(ica.exclude)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualize ICA cleaned epochs (optional)\n",
    "\n",
    "This step can be repeated after each preprocessing step, or you can also do a final inspection at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_faster.plot(n_epochs=10, scalings={'eeg': 20e-6}, title=raw.info['fid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "\n",
    "# If you found a component that should have been excluded but it wasn't you can exclude it here:\n",
    "ica.plot_sources(epochs_faster['rs_3_1'], start=0, stop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "\n",
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "# Document the number of excluded components\n",
    "ica.apply(epochs_rs_faster)\n",
    "epochs_rs_faster.info['description'] = f'n_components: {len(ica.exclude)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save cleaned epochs (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to epoch files\n",
    "interim_epochs_path = os.path.join(interim_path, raw.info['condition'], 'epochs')\n",
    "if not os.path.exists(interim_epochs_path):\n",
    "    os.makedirs(interim_epochs_path)\n",
    "\n",
    "# Save ICA cleaned epochs \n",
    "fid = epochs_faster.info['fid']\n",
    "epochs_clean_fname = f'{fid}_ICA'\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_faster.save(os.path.join(interim_epochs_path, f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = run_autoreject(epochs_faster, n_jobs=11, subset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop bad epochs (stage 1)\n",
    "\n",
    "reject_log = ar.get_reject_log(epochs_faster)\n",
    "\n",
    "epochs_autoreject = epochs_faster.copy().drop(reject_log.bad_epochs, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop bad epochs (stage 2) - after visual inspection\n",
    "idx = np.where(np.count_nonzero(reject_log.labels, axis=1) > epochs_faster.info['nchan']/2)[0].tolist()\n",
    "\n",
    "# # Plot just the bad epochs!\n",
    "if idx: \n",
    "    epochs_faster[idx].plot(n_epochs=10,\n",
    "                                scalings={'eeg': 20e-6},\n",
    "                                n_channels=32)\n",
    "    \n",
    "epochs_autoreject.drop(idx, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_autoreject.drop(idx, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean epochs\n",
    "fid = epochs_autoreject.info['fid']\n",
    "epochs_clean_fname = f'{fid}_ICA_autoreject'\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_autoreject.save(os.path.join(interim_epochs_path, f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac = run_ransac(epochs_autoreject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect which sensors were interpolated (if any)\n",
    "epochs_ransac.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final visual inspection\n",
    "\n",
    "Mark epochs that should be dropped, select electrodes that should be interpolated etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.plot(n_epochs=10,\n",
    "                       n_channels=32,\n",
    "                       # group_by='position',\n",
    "                       scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are additional channels marked for interpolation, we can interpolate them here.\n",
    "\n",
    "if epochs_ransac.info['bads']:\n",
    "    bads_str = ', '.join(epochs_ransac.info['bads'])\n",
    "    epochs_ransac.interpolate_bads()\n",
    "    epochs_ransac.info.update(description=epochs_ransac.info['description'] + ', interpolated: ' + bads_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Set average reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.set_eeg_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Annotate continuous data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = [epochs.events[idx][0] / raw.info['sfreq'] \n",
    "               for idx, value in enumerate(epochs_ransac.drop_log) if value]\n",
    "\n",
    "duration = (epochs_ransac.events[1][0] - epochs_ransac.events[0][0]) / raw.info['sfreq'] \n",
    "\n",
    "raw.annotations.append(onset=start_times,\n",
    "                       duration=[duration] * len(start_times),\n",
    "                       description='BAD_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to annotated files\n",
    "annotated_raw_path = os.path.join(interim_path, raw.info['condition'], 'raw')\n",
    "if not os.path.exists(annotated_raw_path):\n",
    "    os.makedirs(annotated_raw_path)\n",
    "\n",
    "# Save annotated continuous data\n",
    "fid = raw.info[\"fid\"]\n",
    "raw_annotated_fname = f'{fid}_bad_annotated'\n",
    "postfix = '-raw.fif.gz'\n",
    "raw.save(os.path.join(annotated_raw_path, f'{raw_annotated_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save cleaned epochs\n",
    "\n",
    "#### 7.1. Resting period before ASRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to annotated files\n",
    "epochs_rs_path = os.path.join(interim_path, raw.info['condition'], 'epochs_rs')\n",
    "if not os.path.exists(epochs_rs_path):\n",
    "    os.makedirs(epochs_rs_path)\n",
    "\n",
    "rs_period_name = f'rs_{raw.info[\"num_day\"]}_1'\n",
    "fid = f'{raw.info[\"subject\"]}_{raw.info[\"condition\"]}_{rs_period_name}'\n",
    "epochs_clean_fname = f'{fid}_ICA_autoreject_ransac'\n",
    "postfix = '-epo.fif.gz'\n",
    "\n",
    "epochs_ransac[rs_period_name].save(os.path.join(epochs_rs_path, f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Resting period before ASRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_period_name = f'rs_{raw.info[\"num_day\"]}_2'\n",
    "fid = f'{raw.info[\"subject\"]}_{raw.info[\"condition\"]}_{rs_period_name}'\n",
    "epochs_clean_fname = f'{fid}_ICA_autoreject_ransac'\n",
    "postfix = '-epo.fif.gz'\n",
    "\n",
    "epochs_ransac[rs_period_name].save(os.path.join(epochs_rs_path,\n",
    "                                                f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. ASRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to annotated files\n",
    "epochs_asrt_path = os.path.join(interim_path, raw.info['condition'], 'epochs_asrt')\n",
    "if not os.path.exists(epochs_asrt_path):\n",
    "    os.makedirs(epochs_asrt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence, periods in events.groupby('sequence')['event'].apply(set).to_dict().items():\n",
    "    #epochs_to_merge = [epochs_ransac[period] for period in periods]\n",
    "    #merged_epochs = mne.concatenate_epochs(epochs_to_merge, offset=True)\n",
    "    fid = f'{raw.info[\"subject\"]}_{raw.info[\"condition\"]}_asrt_{raw.info[\"num_day\"]}_{sequence}'\n",
    "    epochs_clean_fname = f'{fid}_ICA_autoreject_ransac'\n",
    "    postfix = '-epo.fif.gz'\n",
    "    \n",
    "    epochs_ransac[sorted(set(periods))].save(os.path.join(epochs_asrt_path,\n",
    "                                                          f'{epochs_clean_fname}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup from memory\n",
    "del raw, epochs, epochs_autoreject, epochs_ransac\n",
    "\n",
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}